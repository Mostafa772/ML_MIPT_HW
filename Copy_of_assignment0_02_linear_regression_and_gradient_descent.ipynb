{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mostafa772/ML_MIPT_HW/blob/hw2_lin_reg/Copy_of_assignment0_02_linear_regression_and_gradient_descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqEpGyyyGE1Z",
        "tags": [
          "pdf-title"
        ]
      },
      "source": [
        "## Solving the linear regression problem with gradient descent\n",
        "\n",
        "Today we rewise the linear regression algorithm and it's gradient solution.\n",
        "\n",
        "Your main goal will be to __derive and implement the gradient of MSE, MAE, L1 and L2 regularization terms__ respectively in general __vector form__ (when both single observation $\\mathbf{x}_i$ and corresponding target value $\\mathbf{y}_i$ are vectors).\n",
        "\n",
        "This techniques will be useful later in Deep Learning module of our course as well.\n",
        "\n",
        "We will work with [Boston housing prices dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) subset, which have been preprocessed for your convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbZ-_F1Wzc7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54414e6e-7599-42f9-c131-d0cddd8b4e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-22 18:24:47--  https://raw.githubusercontent.com/girafe-ai/ml-course/22f_basic/homeworks/assignment0_02_lin_reg/loss_and_derivatives.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4600 (4.5K) [text/plain]\n",
            "Saving to: ‘loss_and_derivatives.py.1’\n",
            "\n",
            "\r          loss_and_   0%[                    ]       0  --.-KB/s               \rloss_and_derivative 100%[===================>]   4.49K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-22 18:24:47 (37.7 MB/s) - ‘loss_and_derivatives.py.1’ saved [4600/4600]\n",
            "\n",
            "--2022-11-22 18:24:47--  https://raw.githubusercontent.com/girafe-ai/ml-course/22f_basic/homeworks/assignment0_02_lin_reg/boston_subset.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17921 (18K) [text/plain]\n",
            "Saving to: ‘boston_subset.json.1’\n",
            "\n",
            "boston_subset.json. 100%[===================>]  17.50K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-22 18:24:47 (53.0 MB/s) - ‘boston_subset.json.1’ saved [17921/17921]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "If you are using Google Colab, uncomment the next lines to download `loss_and_derivatives.py` and `boston_subset.json`\n",
        "You can open and change downloaded `.py` files in Colab using the \"Files\" sidebar on the left.\n",
        "'''\n",
        "\n",
        "!wget https://raw.githubusercontent.com/girafe-ai/ml-course/22f_basic/homeworks/assignment0_02_lin_reg/loss_and_derivatives.py\n",
        "!wget https://raw.githubusercontent.com/girafe-ai/ml-course/22f_basic/homeworks/assignment0_02_lin_reg/boston_subset.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lQUR89nGE1f"
      },
      "outputs": [],
      "source": [
        "# Run some setup code for this notebook.\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Some more magic so that the notebook will reload external python modules;\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGf3ShTNGE1q"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('boston_subset.json', 'r') as iofile:\n",
        "    dataset = json.load(iofile)\n",
        "feature_matrix = np.array(dataset['data'])\n",
        "targets = np.array(dataset['target'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIUU1cOZGE10"
      },
      "source": [
        "## Warming up: matrix differentiation\n",
        "_You will meet these questions later in Labs as well, so we highly recommend to answer them right here._\n",
        "\n",
        "Credits: this theoretical part is copied from [YSDA Practical_DL course](https://github.com/yandexdataschool/Practical_DL/tree/spring2019/homework01) homework01."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvrZt_xNGE12"
      },
      "source": [
        "Since it easy to google every task please please please try to understand what's going on. The \"just answer\" thing will not be  counted, make sure to present derivation of your solution. It is absolutely OK if you will find an answer on web then just exercise in $\\LaTeX$ copying it into here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty4m156yGE15"
      },
      "source": [
        "Useful links: \n",
        "[1](http://www.machinelearning.ru/wiki/images/2/2a/Matrix-Gauss.pdf)\n",
        "[2](http://www.atmos.washington.edu/~dennis/MatrixCalculus.pdf)\n",
        "[3](http://cal.cs.illinois.edu/~johannes/research/matrix%20calculus.pdf)\n",
        "[4](http://research.microsoft.com/en-us/um/people/cmbishop/prml/index.htm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8StFOCFGE17"
      },
      "source": [
        "#### Inline question 1\n",
        "$$  \n",
        "y = x^Tx,  \\quad x \\in \\mathbb{R}^N \n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{dy}{dx} = \n",
        "$$ \n",
        "The answer:\n",
        "$$\n",
        " \\sum_{i = j = 1}^{+\\infty} \\ x_{i}*x_{j} = (x_1*x_1 + x_2*x_2 +...)  = (x_1^2 + x_2^2 + ...) \\\\\n",
        "\\frac{dy}{dx} = (2x_1 + 2x_2 + ... ) = 2(x_1 + x_2 +...) = 2x \n",
        "$$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtnNCP4JGE19"
      },
      "source": [
        "#### Inline question 2\n",
        "$$ y = tr(AB) \\quad A,B \\in \\mathbb{R}^{N \\times N} $$ \n",
        "\n",
        "$$\n",
        "\\frac{dy}{dA} = \n",
        "$$\n",
        "\n",
        "***The answer***: assume we have A  and B then thier product will be the product of the columns and the rows. After that we take the trace and we are differentiating according to A so we will end up with only the elements of B transposed.\n",
        "\n",
        "\n",
        "$$\n",
        "\\frac{dy}{dA} = B^T\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWfcC7_dGE2A"
      },
      "source": [
        "#### Inline question 3\n",
        "$$  \n",
        "y = x^TAc , \\quad A\\in \\mathbb{R}^{N \\times N}, x\\in \\mathbb{R}^{N}, c\\in \\mathbb{R}^{N} \n",
        "$$\n",
        "\n",
        "**The answer** is in proposition 7 from the second source:\n",
        "$$\n",
        "\\frac{dy}{dx} = x^TA^T\n",
        "$$\n",
        "<br/> <br/>\n",
        "we get this result from the first source\n",
        "$$\n",
        "\\frac{dy}{dA} = xc^T\n",
        "$$\n",
        "\n",
        "Hint for the latter (one of the ways): use *ex. 2* result and the fact \n",
        "$$\n",
        "tr(ABC) = tr (CAB)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbBc_5FhGE2B"
      },
      "source": [
        "## Loss functions and derivatives implementation\n",
        "You will need to implement the methods from `loss_and_derivatives.py` to go further.\n",
        "__In this assignment we ignore the bias term__, so the linear model takes simple form of \n",
        "$$\n",
        "\\hat{\\mathbf{y}} = XW\n",
        "$$\n",
        "where no extra column of 1s is added to the $X$ matrix.\n",
        "\n",
        "Implement the loss functions, regularization terms and their derivatives with reference to (w.r.t.) weight matrix. \n",
        "\n",
        "__Once again, you can assume that linear model is not required for bias term for now. The dataset is preprocessed for this case.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-CX9dTLGE1y"
      },
      "source": [
        "Autoreload is a great stuff, but sometimes it does not work as intended. The code below aims to fix that. __Do not forget to save your changes in the `.py` file before reloading the desired functions.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtELlRTOGE2E",
        "tags": [
          "pdf-ignore"
        ]
      },
      "outputs": [],
      "source": [
        "# This dirty hack might help if the autoreload has failed for some reason\n",
        "try:\n",
        "    del LossAndDerivatives\n",
        "except:\n",
        "    pass\n",
        "\n",
        "from loss_and_derivatives import LossAndDerivatives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aGWExkQzc7T"
      },
      "source": [
        "Mention, that in this case we compute the __MSE__ and __MAE__ for vector __y__. In the reference implementation we are averaging the error along the __y__ dimentionality as well.\n",
        "\n",
        "E.g. for residuals vector $[1., 1., 1., 1.]$ the averaged error value will be $\\frac{1}{4}(1. + 1. + 1. + 1.)$ \n",
        "\n",
        "This may be needed to get the desired mutliplier for loss functions derivatives. You also can refer to the `.mse` method implementation, which is already available in the `loss_and_derivatives.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71VCxUwHGE2L"
      },
      "outputs": [],
      "source": [
        "w = np.array([1., 1.])\n",
        "x_n, y_n = feature_matrix, targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMN81aYyGE2T"
      },
      "source": [
        "Here come several asserts to check yourself:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKUYnPWuGE2V"
      },
      "outputs": [],
      "source": [
        "w = np.array([1., 1.])\n",
        "x_n, y_n = feature_matrix, targets\n",
        "\n",
        "# Repeating data to make everything multi-dimentional\n",
        "w = np.vstack([w[None, :] + 0.27, w[None, :] + 0.22, w[None, :] + 0.45, w[None, :] + 0.1]).T\n",
        "y_n = np.hstack([y_n[:, None], 2*y_n[:, None], 3*y_n[:, None], 4*y_n[:, None]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtkO4hWYGE2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6190a034-551c-4464-ce6f-70a3c901be5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE derivative:\n",
            "[[ 7.32890068 12.88731311 18.82128365 23.97731238]\n",
            " [ 9.55674399 17.05397661 24.98807528 32.01723714]] \n",
            "\n",
            "L2 reg derivative:\n",
            "[[2.54 2.44 2.9  2.2 ]\n",
            " [2.54 2.44 2.9  2.2 ]]\n"
          ]
        }
      ],
      "source": [
        "reference_mse_derivative = np.array([\n",
        "    [ 7.32890068, 12.88731311, 18.82128365, 23.97731238],\n",
        "    [ 9.55674399, 17.05397661, 24.98807528, 32.01723714]\n",
        "])\n",
        "reference_l2_reg_derivative = np.array([\n",
        "    [2.54, 2.44, 2.9 , 2.2 ],\n",
        "    [2.54, 2.44, 2.9 , 2.2 ]\n",
        "])\n",
        "\n",
        "\n",
        "# print(LossAndDerivatives.l2_reg(w))\n",
        "\n",
        "# print( 1/(2*x_n.shape[0]) * np.matmul((x_n.dot(w) - y_n).transpose(), x_n).transpose())\n",
        "\n",
        "# print(LossAndDerivatives.mse_derivative(x_n, y_n, w))\n",
        "\n",
        "assert np.allclose(\n",
        "    reference_mse_derivative,\n",
        "    LossAndDerivatives.mse_derivative(x_n, y_n, w), rtol=1e-3\n",
        "), 'Something wrong with MSE derivative'\n",
        "\n",
        "# print(LossAndDerivatives.l2_reg_derivative(w))\n",
        "\n",
        "assert np.allclose(\n",
        "    reference_l2_reg_derivative,\n",
        "    LossAndDerivatives.l2_reg_derivative(w), rtol=1e-3\n",
        "), 'Something wrong with L2 reg derivative'\n",
        "\n",
        "print(\n",
        "    'MSE derivative:\\n{} \\n\\nL2 reg derivative:\\n{}'.format(\n",
        "        LossAndDerivatives.mse_derivative(x_n, y_n, w),\n",
        "        LossAndDerivatives.l2_reg_derivative(w))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK_xcLJyzc7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d93d5744-dbe1-439b-d308-63a40a8f473d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE derivative:\n",
            "[[0.19708867 0.19621798 0.19621798 0.19572906]\n",
            " [0.25574138 0.25524507 0.25524507 0.25406404]] \n",
            "\n",
            "L1 reg derivative:\n",
            "[[1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0]]\n"
          ]
        }
      ],
      "source": [
        "reference_mae_derivative = np.array([\n",
        "    [0.19708867, 0.19621798, 0.19621798, 0.19572906],\n",
        "    [0.25574138, 0.25524507, 0.25524507, 0.25406404]\n",
        "])\n",
        "\n",
        "reference_l1_reg_derivative = np.array([\n",
        "    [1., 1., 1., 1.],\n",
        "    [1., 1., 1., 1.]\n",
        "])\n",
        "\n",
        "assert np.allclose(\n",
        "    reference_mae_derivative,\n",
        "    LossAndDerivatives.mae_derivative(x_n, y_n, w), rtol=1e-3\n",
        "), 'Something wrong with MAE derivative'\n",
        "\n",
        "\n",
        "assert np.allclose(\n",
        "    reference_l1_reg_derivative,\n",
        "    LossAndDerivatives.l1_reg_derivative(w), rtol=1e-3\n",
        "), 'Something wrong with L1 reg derivative'\n",
        "\n",
        "print(\n",
        "    'MAE derivative:\\n{} \\n\\nL1 reg derivative:\\n{}'.format(\n",
        "        LossAndDerivatives.mae_derivative(x_n, y_n, w),\n",
        "        LossAndDerivatives.l1_reg_derivative(w))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qkTUzYwFKOyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJcSPj8UGE20"
      },
      "source": [
        "### Gradient descent on the real data\n",
        "Here comes small loop with gradient descent algorithm. We compute the gradient over the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On6aSWuIGE21"
      },
      "outputs": [],
      "source": [
        "def get_w_by_grad(X, Y, w_0, loss_mode='mse', reg_mode=None, lr=0.05, n_steps=100, reg_coeff=0.05):\n",
        "    if loss_mode == 'mse':\n",
        "        loss_function = LossAndDerivatives.mse\n",
        "        loss_derivative = LossAndDerivatives.mse_derivative\n",
        "    elif loss_mode == 'mae':\n",
        "        loss_function = LossAndDerivatives.mae\n",
        "        loss_derivative = LossAndDerivatives.mae_derivative\n",
        "    else:\n",
        "        raise ValueError('Unknown loss function. Available loss functions: `mse`, `mae`')\n",
        "    \n",
        "    if reg_mode is None:\n",
        "        reg_function = LossAndDerivatives.no_reg\n",
        "        reg_derivative = LossAndDerivatives.no_reg_derivative # lambda w: np.zeros_like(w)\n",
        "    elif reg_mode == 'l2':\n",
        "        reg_function = LossAndDerivatives.l2_reg\n",
        "        reg_derivative = LossAndDerivatives.l2_reg_derivative\n",
        "    elif reg_mode == 'l1':\n",
        "        reg_function = LossAndDerivatives.l1_reg\n",
        "        reg_derivative = LossAndDerivatives.l1_reg_derivative\n",
        "    else:\n",
        "        raise ValueError('Unknown regularization mode. Available modes: `l1`, `l2`, None')\n",
        "    \n",
        "    \n",
        "    w = w_0.copy()\n",
        "\n",
        "    for i in range(n_steps):\n",
        "        empirical_risk = loss_function(X, Y, w) + reg_coeff * reg_function(w)\n",
        "        gradient = loss_derivative(X, Y, w) + reg_coeff * reg_derivative(w)\n",
        "        gradient_norm = np.linalg.norm(gradient)\n",
        "        if gradient_norm > 5.:\n",
        "            gradient = gradient / gradient_norm * 5.\n",
        "        w -= lr * gradient\n",
        "        \n",
        "        if i % 25 == 0:\n",
        "            print('Step={}, loss={},\\ngradient values={}\\n'.format(i, empirical_risk, gradient))\n",
        "    return w\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVQPTwwZzc7V"
      },
      "source": [
        "Let's check how it works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1pyDIyqGE25"
      },
      "outputs": [],
      "source": [
        "# Initial weight matrix\n",
        "w = np.ones((2,1), dtype=float)\n",
        "y_n = targets[:, None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erTRQiAFGE29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e29d77-d14f-4fe0-f391-518b61aeda0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step=0, loss=231.28353984777308,\n",
            "gradient values=[[3.03842496]\n",
            " [3.9708908 ]]\n",
            "\n",
            "Step=25, loss=63.363170318505695,\n",
            "gradient values=[[1.31396457]\n",
            " [2.31414181]]\n",
            "\n",
            "Step=50, loss=51.3972888034079,\n",
            "gradient values=[[-0.07336478]\n",
            " [ 0.51315667]]\n",
            "\n",
            "Step=75, loss=50.13219634839481,\n",
            "gradient values=[[-0.2014412 ]\n",
            " [ 0.23049528]]\n",
            "\n",
            "Step=100, loss=49.54190461113104,\n",
            "gradient values=[[-0.17602163]\n",
            " [ 0.15744284]]\n",
            "\n",
            "Step=125, loss=49.151714686162435,\n",
            "gradient values=[[-0.13974175]\n",
            " [ 0.11983809]]\n",
            "\n",
            "Step=150, loss=48.874916253265795,\n",
            "gradient values=[[-0.10929036]\n",
            " [ 0.09305891]]\n",
            "\n",
            "Step=175, loss=48.67390737591064,\n",
            "gradient values=[[-0.0852619 ]\n",
            " [ 0.07251197]]\n",
            "\n",
            "Step=200, loss=48.525941255402515,\n",
            "gradient values=[[-0.06648844]\n",
            " [ 0.05653442]]\n",
            "\n",
            "Step=225, loss=48.4158653906066,\n",
            "gradient values=[[-0.05184497]\n",
            " [ 0.04408173]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "w_grad = get_w_by_grad(x_n, y_n, w, loss_mode='mse', reg_mode='l2', n_steps=250)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MfHDbGSzc7W"
      },
      "source": [
        "### Comparing with `sklearn`\n",
        "Finally, let's compare our model with `sklearn` implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ystYDqGCzc7W"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QA_9WO1zc7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a573a4-2f14-45ad-ff7a-020475c0f797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sklearn linear regression implementation delivers MSE = 42.53541245128315\n"
          ]
        }
      ],
      "source": [
        "lr = Ridge(alpha=0.05)\n",
        "lr.fit(x_n, y_n)\n",
        "print('sklearn linear regression implementation delivers MSE = {}'.format(np.mean((lr.predict(x_n) - y_n)**2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gse1m4nyGE3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5931fda-b55a-4331-d0d9-6a44c7067d50"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.scatter(x_n[:, -1], y_n[:, -1])\n",
        "plt.scatter(x_n[:, -1], x_n.dot(w_grad)[:, -1], color='orange', label='Handwritten linear regression', linewidth=5)\n",
        "plt.scatter(x_n[:, -1], lr.predict(x_n), color='cyan', label='sklearn Ridge')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZLOdjzXzc7W"
      },
      "source": [
        "While the solutions may look like a bit different, remember, that handwritten linear regression was unable to fit the bias term, it was equal to $0$ by default."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GgeWdBmGE3H"
      },
      "source": [
        "### Submit your work\n",
        "To submit your work you need to log into Yandex contest (link will be provided later) and upload the `loss_and_derivatives.py` file for the corresponding problem."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}