{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mostafa772/ML_MIPT_HW/blob/hw4_tree/Copy_of_assignment0_04_decision_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLQ-AH9DgNj3"
      },
      "source": [
        "## assignment 04: Decision Tree construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "k1JEgj1VgNj7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ccd383-da60-41b6-fb85-b4a27d58814a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘tree.py’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# If working in colab, uncomment the following line\n",
        "!wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/21f_made/homeworks/assignment0_04_tree/tree.py -nc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "6XRyXguigNj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa85911-e8ba-4916-9dc5-6f62e4166dff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.datasets import make_classification, make_regression, load_digits, load_boston\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ-Xg_qbgNj9"
      },
      "source": [
        "Let's fix the `random_state` (a.k.a. random seed)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "K89yrIm9gNj9"
      },
      "outputs": [],
      "source": [
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGFdPIX6gNj-"
      },
      "source": [
        "__Your ultimate task for today is to impement the `DecisionTree` class and use it to solve classification and regression problems.__\n",
        "\n",
        "__Specifications:__\n",
        "- The class inherits from `sklearn.BaseEstimator`;\n",
        "- Constructor is implemented for you. It has the following parameters:\n",
        "    * `max_depth` - maximum depth of the tree; `np.inf` by default\n",
        "    * `min_samples_split` - minimal number of samples in the leaf to make a split; `2` by default;\n",
        "    * `criterion` - criterion to select the best split; in classification one of `['gini', 'entropy']`, default `gini`; in regression `variance`;\n",
        "\n",
        "- `fit` method takes `X` (`numpy.array` of type `float` shaped `(n_objects, n_features)`) and `y` (`numpy.array` of type float shaped `(n_objects, 1)` in regression; `numpy.array` of type int shaped `(n_objects, 1)` with class labels in classification). It works inplace and fits the `DecisionTree` class instance to the provided data from scratch.\n",
        "\n",
        "- `predict` method takes `X` (`numpy.array` of type `float` shaped `(n_objects, n_features)`) and returns the predicted $\\hat{y}$ values. In classification it is a class label for every object (the most frequent in the leaf; if several classes meet this requirement select the one with the smallest class index). In regression it is the desired constant (e.g. mean value for `variance` criterion)\n",
        "\n",
        "- `predict_proba` method (works only for classification (`gini` or `entropy` criterion). It takes `X` (`numpy.array` of type `float` shaped `(n_objects, n_features)`) and returns the `numpy.array` of type `float` shaped `(n_objects, n_features)` with class probabilities for every object from `X`. Class $i$ probability equals the ratio of $i$ class objects that got in this node in the training set.\n",
        "\n",
        "    \n",
        "__Small recap:__\n",
        "\n",
        "To find the optimal split the following functional is evaluated:\n",
        "    \n",
        "$$G(j, t) = H(Q) - \\dfrac{|L|}{|Q|} H(L) - \\dfrac{|R|}{|Q|} H(R),$$\n",
        "    where $Q$ is the dataset from the current node, $L$ and $R$ are left and right subsets defined by the split $x^{(j)} < t$.\n",
        "\n",
        "\n",
        "\n",
        "1. Classification. Let $p_i$ be the probability of $i$ class in subset $X$ (ratio of the $i$ class objects in the dataset). The criterions are defined as:\n",
        "    \n",
        "    * `gini`: Gini impurity $$H(R) = 1 -\\sum_{i = 1}^K p_i^2$$\n",
        "    \n",
        "    * `entropy`: Entropy $$H(R) = -\\sum_{i = 1}^K p_i \\log(p_i)$$ (One might use the natural logarithm).\n",
        "    \n",
        "2. Regression. Let $y_l$ be the target value for the $R$, $\\mathbf{y} = (y_1, \\dots, y_N)$ – all targets for the selected dataset $X$.\n",
        "    \n",
        "    * `variance`: $$H(R) = \\dfrac{1}{|R|} \\sum_{y_j \\in R}(y_j - \\text{mean}(\\mathbf{y}))^2$$\n",
        "    \n",
        "    * `mad_median`: $$H(R) = \\dfrac{1}{|R|} \\sum_{y_j \\in R}|y_j - \\text{median}(\\mathbf{y})|$$\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwiNkCibgNj_"
      },
      "source": [
        "**Hints and comments**:\n",
        "\n",
        "* No need to deal with categorical features, they will not be present.\n",
        "* Siple greedy recursive procedure is enough. However, you can speed it up somehow (e.g. using percentiles).\n",
        "* Please, do not copy implementations available online. You are supposed to build very simple example of the Decision Tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ8_MwNBgNkA"
      },
      "source": [
        "File `tree.py` is waiting for you. Implement all the needed methods in that file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI0ULazggNkA"
      },
      "source": [
        "### Check yourself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "XEwLfEkWgNkB"
      },
      "outputs": [],
      "source": [
        "from tree import entropy, gini, variance, mad_median, DecisionTree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8KLhYYkgNkB"
      },
      "source": [
        "#### Simple check"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(n_classes, y):\n",
        "    y_one_hot = np.zeros((len(y), n_classes), dtype=float)\n",
        "    y_one_hot[np.arange(len(y)), y.astype(int)[:, 0]] = 1.\n",
        "    return y_one_hot"
      ],
      "metadata": {
        "id": "XvQ1Ycks2TlQ"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.ones((4, 5), dtype=float) * np.arange(4)[:, None]\n",
        "y = np.arange(4)[:, None] + np.asarray([0.2, -0.3, 0.1, 0.4])[:, None]\n",
        "y= y.T[0]\n",
        "# med = np.median(y)\n",
        "# print(y - med)\n",
        "# print(np.median(y))\n",
        "probabilities = []\n",
        "\n",
        "# for each unique label calculate the probability for it\n",
        "for one_class in np.unique(y):\n",
        "    proba = y[y == one_class].shape[0] / y.shape[0]\n",
        "    probabilities.append(proba)\n",
        "print(probabilities)\n",
        "# print(np.median(y))\n",
        "\n",
        "# y_one_hot = one_hot_encode(y.shape[0], y)\n",
        "# print(y_one_hot.shape)\n",
        "# for class_ in [0,1]:\n",
        "#     print(class_)\n",
        "#     print(y_one_hot[y_one_hot == class_].shape[0]/ y_one_hot.shape[0])\n",
        "# print(y_one_hot[y_one_hot == 0].shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzJeEw2V2VuX",
        "outputId": "d7e1b709-de06-4230-cebc-8c54fcba2242"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.25, 0.25, 0.25, 0.25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "v9RAtUcSgNkB"
      },
      "outputs": [],
      "source": [
        "X = np.ones((4, 5), dtype=float) * np.arange(4)[:, None]\n",
        "y = np.arange(4)[:, None] + np.asarray([0.2, -0.3, 0.1, 0.4])[:, None]\n",
        "class_estimator = DecisionTree(max_depth=10, criterion_name='gini')\n",
        "# print(X)\n",
        "# print(y)\n",
        "(X_l, y_l), (X_r, y_r) = class_estimator.make_split(1, 1., X, y)\n",
        "assert np.array_equal(X[:1], X_l)\n",
        "assert np.array_equal(X[1:], X_r)\n",
        "assert np.array_equal(y[:1], y_l)\n",
        "assert np.array_equal(y[1:], y_r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKoMG_85gNkC"
      },
      "source": [
        "#### Classification problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "dMiaBAtggNkC"
      },
      "outputs": [],
      "source": [
        "digits_data = load_digits().data\n",
        "digits_target = load_digits().target[:, None] # to make the targets consistent with our model interfaces\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_target, test_size=0.2, random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "FChRTan8gNkC"
      },
      "outputs": [],
      "source": [
        "assert len(y_train.shape) == 2 and y_train.shape[0] == len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "uuf7axsYgNkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef9ca073-5345-4ce0-b51e-7990c7e9d69c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8555555555555555\n"
          ]
        }
      ],
      "source": [
        "class_estimator = DecisionTree(max_depth=10, criterion_name='gini')\n",
        "class_estimator.fit(X_train, y_train)\n",
        "ans = class_estimator.predict(X_test)\n",
        "accuracy_gini = accuracy_score(y_test, ans)\n",
        "print(accuracy_gini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "pACnAm7GgNkD"
      },
      "outputs": [],
      "source": [
        "reference = np.array([0.09027778, 0.09236111, 0.08333333, 0.09583333, 0.11944444,\n",
        "       0.13888889, 0.09930556, 0.09444444, 0.08055556, 0.10555556])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "mvZbMiS9gNkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f243f32-433e-4486-847c-adf333828ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8777777777777778\n"
          ]
        }
      ],
      "source": [
        "class_estimator = DecisionTree(max_depth=10, criterion_name='entropy')\n",
        "class_estimator.fit(X_train, y_train)\n",
        "ans = class_estimator.predict(X_test)\n",
        "accuracy_entropy = accuracy_score(y_test, ans)\n",
        "print(accuracy_entropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "2d6fnKhOgNkD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "e01578dd-aa67-4863-f31a-398d4002115b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-193-f669dd295d17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m  \u001b[0;36m0.84\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0maccuracy_gini\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m  \u001b[0;36m0.86\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0maccuracy_entropy\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "assert  0.84 < accuracy_gini < 0.9\n",
        "assert  0.86 < accuracy_entropy < 0.9\n",
        "assert np.sum(np.abs(class_estimator.predict_proba(X_test).mean(axis=0) - reference)) < 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sbD1ddsgNkD"
      },
      "source": [
        "Let's use 5-fold cross validation (`GridSearchCV`) to find optimal values for `max_depth` and `criterion` hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3haGa7MOgNkE"
      },
      "outputs": [],
      "source": [
        "param_grid = {'max_depth': range(3,11), 'criterion_name': ['gini', 'entropy']}\n",
        "gs = GridSearchCV(DecisionTree(), param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtOSUjfAgNkE"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "gs.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9pYphvvgNkE"
      },
      "outputs": [],
      "source": [
        "gs.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYyRps9kgNkE"
      },
      "outputs": [],
      "source": [
        "assert gs.best_params_['criterion_name'] == 'entropy'\n",
        "assert 6 < gs.best_params_['max_depth'] < 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "153fShV4gNkE"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "plt.title(\"The dependence of quality on the depth of the tree\")\n",
        "plt.plot(np.arange(3,11), gs.cv_results_['mean_test_score'][:8], label='Gini')\n",
        "plt.plot(np.arange(3,11), gs.cv_results_['mean_test_score'][8:], label='Entropy')\n",
        "plt.legend(fontsize=11, loc=1)\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn1g_7xhgNkF"
      },
      "source": [
        "#### Regression problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "-9eKeZm3gNkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c629a0d-b350-4c9e-e890-badee18cbaab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "regr_data = load_boston().data\n",
        "regr_target = load_boston().target[:, None] # to make the targets consistent with our model interfaces\n",
        "RX_train, RX_test, Ry_train, Ry_test = train_test_split(regr_data, regr_target, test_size=0.2, random_state=RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "FwZ-LThngNkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598ebb99-e39d-4146-bcbf-5e92372d91cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.87733988449203\n"
          ]
        }
      ],
      "source": [
        "regressor = DecisionTree(max_depth=10, criterion_name='mad_median')\n",
        "regressor.fit(RX_train, Ry_train)\n",
        "predictions_mad = regressor.predict(RX_test)\n",
        "mse_mad = mean_squared_error(Ry_test, predictions_mad)\n",
        "print(mse_mad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "57pwkurPgNkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7267b07-f7ae-4a4a-929b-b2354ccdbc66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.334699122818508\n"
          ]
        }
      ],
      "source": [
        "regressor = DecisionTree(max_depth=10, criterion_name='variance')\n",
        "regressor.fit(RX_train, Ry_train)\n",
        "predictions_mad = regressor.predict(RX_test)\n",
        "mse_var = mean_squared_error(Ry_test, predictions_mad)\n",
        "print(mse_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "6L70uHE9gNkF"
      },
      "outputs": [],
      "source": [
        "assert 9 < mse_mad < 20\n",
        "assert 8 < mse_var < 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "id": "FtxfuI0ZgNkF"
      },
      "outputs": [],
      "source": [
        "param_grid_R = {'max_depth': range(2,9), 'criterion_name': ['variance', 'mad_median']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "KoUmeHpCgNkF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24fb2fc9-4ae2-433b-ca8e-d231fd07e80d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=DecisionTree(), n_jobs=-2,\n",
              "             param_grid={'criterion_name': ['variance', 'mad_median'],\n",
              "                         'max_depth': range(2, 9)},\n",
              "             scoring='neg_mean_squared_error')"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ],
      "source": [
        "gs_R = GridSearchCV(DecisionTree(), param_grid=param_grid_R, cv=5, scoring='neg_mean_squared_error', n_jobs=-2)\n",
        "gs_R.fit(RX_train, Ry_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "NVplr8BegNkG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a438311-120b-489f-b2fe-940392fc593e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion_name': 'mad_median', 'max_depth': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ],
      "source": [
        "gs_R.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "8FymGzukgNkG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "b95bb670-90a8-43a0-89ef-8b99f0261aab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-206-4a97299e3c77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mgs_R\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'criterion_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mad_median'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mgs_R\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "assert gs_R.best_params_['criterion_name'] == 'mad_median'\n",
        "assert 3 < gs_R.best_params_['max_depth'] < 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeaEN1HagNkG"
      },
      "outputs": [],
      "source": [
        "var_scores = gs_R.cv_results_['mean_test_score'][:7]\n",
        "mad_scores = gs_R.cv_results_['mean_test_score'][7:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okEnxJg8gNkG"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "plt.title(\"The dependence of neg_mse on the depth of the tree\")\n",
        "plt.plot(np.arange(2,9), var_scores, label='variance')\n",
        "plt.plot(np.arange(2,9), mad_scores, label='mad_median')\n",
        "plt.legend(fontsize=11, loc=1)\n",
        "plt.xlabel(\"max_depth\")\n",
        "plt.ylabel('neg_mse')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}